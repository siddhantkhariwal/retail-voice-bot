{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Library and project credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vertexai.language_models import TextEmbeddingInput, TextEmbeddingModel\n",
    "import pdfplumber\n",
    "import numpy as np\n",
    "PROJECT_ID = \"walmart-retail-media\"\n",
    "MODEL_ID = \"text-embedding-004\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-trained Embedding model text-embedding-004 to create embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ExtractCreateEmbeddings:\n",
    "\n",
    "    def __init__(self, file_path):\n",
    "        self.model = TextEmbeddingModel.from_pretrained(\"text-embedding-004\")\n",
    "        self.path = file_path\n",
    "        print(\"PAth:::   \", self.path)\n",
    "\n",
    "\n",
    "    def embed_text(self, text: list):\n",
    "        embeddings = self.model.get_embeddings([text])\n",
    "        res = []\n",
    "        for embedding in embeddings:\n",
    "            res.append(embedding.values)\n",
    "            # print(len(embedding.values))\n",
    "        # print(len(res))\n",
    "        return res\n",
    "   \n",
    "\n",
    "    # Function to extract text from PDF\n",
    "    def extract_text_from_pdf(self):\n",
    "        # Open the PDF file\n",
    "        with pdfplumber.open(self.path) as pdf:\n",
    "            all_text = \"\"\n",
    "            extract = []\n",
    "            # Iterate over all the pages\n",
    "            for i, page in enumerate(pdf.pages):\n",
    "                text = page.extract_text()  # Extract text from each page\n",
    "                if text:\n",
    "                    embed = self.embed_text(text)\n",
    "                    # extract.append([text,embed[0]])\n",
    "                    # extract[f\"page_{i+1}\"] = [text, embed[0]]\n",
    "                    extract.append([text, embed[0]])\n",
    "                print(f\"Extracted text from page {i + 1}\")\n",
    "\n",
    "            return extract\n",
    "        \n",
    "def embed_text(text: list):\n",
    "        model = TextEmbeddingModel.from_pretrained(\"text-embedding-004\")\n",
    "        embeddings = model.get_embeddings([text])\n",
    "        res = []\n",
    "        for embedding in embeddings:\n",
    "            res.append(embedding.values)\n",
    "            # print(len(embedding.values))\n",
    "        # print(len(res))\n",
    "        return res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# creating embedding for the uploaded pdf file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Contents\\nSr No Content Page number\\nWelcome and general guidelines\\nBusiness Ethics\\n1 Code of Conduct 4-10\\nBenefits\\n2 Leave Policy 11-20\\n3 Expense Reimbursement 21-23\\n4 Relocation Policy – Within India 24 – 25\\n5 Relocation Policy – Any country to India 26 – 27\\nTredence Academy of Lots of Learning\\n6 U Learn V Pay 28 – 30\\nReward & Performance\\n7 Reward and Recognition 31-35\\n8 Performance Management 36-37\\nCompliance\\n9 Privacy and Confidentiality Policy 38\\n10 Intellectual property Policy 39-42\\n11 Conflict of Interest Policy 43-45\\n12 POSH Policy 46-55\\nOthers\\n13 Exit Policy 56-58\\nAnnexure\\n14 Acceptable Usage Policy (AUP) 60-78\\n1\\nEmployee Handbook 2024-India | TRE-ISMS-DP-001 | CONFIDENTIAL'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_values[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PAth:::    C:\\Users\\manjuprasad.n\\Downloads\\India Employee Handbook - 2024.pdf\n",
      "Extracted text from page 1\n",
      "Extracted text from page 2\n",
      "Extracted text from page 3\n",
      "Extracted text from page 4\n",
      "Extracted text from page 5\n",
      "Extracted text from page 6\n",
      "Extracted text from page 7\n",
      "Extracted text from page 8\n",
      "Extracted text from page 9\n",
      "Extracted text from page 10\n",
      "Extracted text from page 11\n",
      "Extracted text from page 12\n",
      "Extracted text from page 13\n",
      "Extracted text from page 14\n",
      "Extracted text from page 15\n",
      "Extracted text from page 16\n",
      "Extracted text from page 17\n",
      "Extracted text from page 18\n",
      "Extracted text from page 19\n",
      "Extracted text from page 20\n",
      "Extracted text from page 21\n",
      "Extracted text from page 22\n",
      "Extracted text from page 23\n",
      "Extracted text from page 24\n",
      "Extracted text from page 25\n",
      "Extracted text from page 26\n",
      "Extracted text from page 27\n",
      "Extracted text from page 28\n",
      "Extracted text from page 29\n",
      "Extracted text from page 30\n",
      "Extracted text from page 31\n",
      "Extracted text from page 32\n",
      "Extracted text from page 33\n",
      "Extracted text from page 34\n",
      "Extracted text from page 35\n",
      "Extracted text from page 36\n",
      "Extracted text from page 37\n",
      "Extracted text from page 38\n",
      "Extracted text from page 39\n",
      "Extracted text from page 40\n",
      "Extracted text from page 41\n",
      "Extracted text from page 42\n",
      "Extracted text from page 43\n",
      "Extracted text from page 44\n",
      "Extracted text from page 45\n",
      "Extracted text from page 46\n",
      "Extracted text from page 47\n",
      "Extracted text from page 48\n",
      "Extracted text from page 49\n",
      "Extracted text from page 50\n",
      "Extracted text from page 51\n",
      "Extracted text from page 52\n",
      "Extracted text from page 53\n",
      "Extracted text from page 54\n",
      "Extracted text from page 55\n",
      "Extracted text from page 56\n",
      "Extracted text from page 57\n",
      "Extracted text from page 58\n",
      "Extracted text from page 59\n",
      "Extracted text from page 60\n",
      "Extracted text from page 61\n",
      "Extracted text from page 62\n",
      "Extracted text from page 63\n",
      "Extracted text from page 64\n",
      "Extracted text from page 65\n",
      "Extracted text from page 66\n",
      "Extracted text from page 67\n",
      "Extracted text from page 68\n",
      "Extracted text from page 69\n",
      "Extracted text from page 70\n",
      "Extracted text from page 71\n",
      "Extracted text from page 72\n",
      "Extracted text from page 73\n",
      "Extracted text from page 74\n",
      "Extracted text from page 75\n",
      "Extracted text from page 76\n",
      "Extracted text from page 77\n",
      "Extracted text from page 78\n",
      "Extracted text from page 79\n"
     ]
    }
   ],
   "source": [
    "file_path=r\"C:\\Users\\manjuprasad.n\\Downloads\\India Employee Handbook - 2024.pdf\"\n",
    "embed = ExtractCreateEmbeddings(file_path)\n",
    "embed_values= embed.extract_text_from_pdf()  \n",
    "embedded_vectors,text = [],[]\n",
    "for i in range(len(embed_values)):\n",
    "    embedded_vectors.append(embed_values[i][1])\n",
    "    text.append(embed_values[i][0])\n",
    "\n",
    "np_vectors = np.array(embedded_vectors)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating collection in Qdrant DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient, models\n",
    "\n",
    "# Connect to Qdrant (local instance)\n",
    "client = QdrantClient(url=\"http://localhost:6333\")\n",
    "\n",
    "# Define collection name\n",
    "collection_name = \"my_cosine_collection\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection 'my_cosine_collection' created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Create a new collection with 100-dimensional vectors and Cosine similarity\n",
    "client.create_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config=models.VectorParams(size=100, distance=models.Distance.COSINE)\n",
    ")\n",
    "\n",
    "print(f\"Collection '{collection_name}' created successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storing vector embedding in qdrant db collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "\n",
    "# Initialize Qdrant client\n",
    "client = QdrantClient(url=\"http://localhost:6333\")\n",
    "\n",
    "collection_name = \"my_cosine_collection\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert embeddings into Qdrant\n",
    "client.upload_points(\n",
    "    collection_name=collection_name,\n",
    "    points=[\n",
    "        models.PointStruct(id=i, vector=embedded_vectors[i], payload={\"text\": text[i]})\n",
    "        for i in range(len(embedded_vectors))\n",
    "    ]\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating embedding for questions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions=['Types of expenses covered for relocation pplicy within India',\n",
    "           'What are half yearly awards',\n",
    "           'What is the criteria for PAT on the back']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_embed=[]\n",
    "from rag.create_embedding import embed_text\n",
    "for q in questions:\n",
    "    target_vector = np.array(embed_text(q))\n",
    "    q_embed.append(target_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding similary b/w responses and questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from utils.config import cos_top_n, knn_top_n\n",
    "\n",
    "\n",
    "class SimilaritySearch:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.top_n = cos_top_n\n",
    "        # Initialize the NearestNeighbors model with cosine similarity\n",
    "        self.knn_model = NearestNeighbors(n_neighbors=knn_top_n, metric='manhattan')\n",
    "\n",
    "    # Function to perform KNN similarity search using cosine similarity\n",
    "    def knn_similarity_search(self, target_vector, vectors):\n",
    "        # Fit the model on the dataset of vectors\n",
    "        self.knn_model.fit(vectors)\n",
    "        \n",
    "        # Reshape target vector to 2D (as required by scikit-learn)\n",
    "        target_vector = np.array(target_vector).reshape(1, -1)\n",
    "        \n",
    "        # Perform the KNN search\n",
    "        distances, indices = self.knn_model.kneighbors(target_vector)\n",
    "        \n",
    "        # Return the indices of the nearest vectors and their distances\n",
    "        return indices.flatten(), distances.flatten()\n",
    "\n",
    "\n",
    "    # Function to compute cosine similarity and return top N most similar vectors\n",
    "    def cosine_similarity_search(self, target_vector, vectors):\n",
    "        # Reshape target_vector to 2D since cosine_similarity expects 2D arrays\n",
    "        target_vector = np.array(target_vector).reshape(1, -1)\n",
    "        \n",
    "        # Compute cosine similarities between the target vector and all other vectors\n",
    "        similarities = cosine_similarity(vectors, target_vector)\n",
    "        \n",
    "        # Flatten the result array\n",
    "        similarities = similarities.flatten()\n",
    "\n",
    "        # Get indices of top N most similar vectors (in descending order of similarity)\n",
    "        top_n_indices = similarities.argsort()[::-1][:self.top_n]\n",
    "        \n",
    "        # Get corresponding similarity scores\n",
    "        top_n_similarities = similarities[top_n_indices]\n",
    "        return top_n_indices, top_n_similarities\n",
    "    \n",
    "\n",
    "\n",
    "    def search(self, target_vector, vectors):\n",
    "        \n",
    "        knn_top_indices, knn_top_distances = self.knn_similarity_search(target_vector, vectors)\n",
    "        cos_top_indices, cos_top_similarities = self.cosine_similarity_search(target_vector, vectors)\n",
    "\n",
    "       \n",
    "        \n",
    "        return cos_top_indices,cos_top_similarities,knn_top_indices,knn_top_distances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Types of expenses covered for relocation pplicy within India', '24,0.73167514891693', '26,0.7234795860880974', '25,0.7206877359265444', '26,16.31082082206285', '24,16.39321315582947', '25,16.624978481821927'], ['What are half yearly awards', '33,0.6012876925602934', '34,0.5745539086034994', '32,0.5488804145321222', '33,19.63542295501611', '34,20.477088664374605', '32,21.018170781212348'], ['What is the criteria for PAT on the back', '36,0.4221254111180226', '58,0.38948894705687287', '33,0.38037380928989345', '36,23.795754771310385', '58,24.214489592352038', '33,24.60175469755268']]\n"
     ]
    }
   ],
   "source": [
    "formatted_output = []\n",
    "ss=SimilaritySearch()\n",
    "context_pages_ouput=[]\n",
    "for qr in range(len(questions)):  \n",
    "    cos_top_indices, cos_top_similarities, knn_top_indices, knn_top_distances = ss.search(target_vector=q_embed[qr], vectors=np_vectors)\n",
    "    output = [questions[qr]] \n",
    "    context_pages = set()\n",
    "    for i in cos_top_indices:\n",
    "        context_pages.add(i)\n",
    "    for i in knn_top_indices:\n",
    "            context_pages.add(i)\n",
    "    for idx, similarity in zip(cos_top_indices, cos_top_similarities):\n",
    "        output.append(f\"{idx},{similarity}\")\n",
    "    for idx, distance in zip(knn_top_indices, knn_top_distances):\n",
    "        output.append(f\"{idx},{distance}\")\n",
    "    formatted_output.append(output)\n",
    "    context_pages_ouput.append(context_pages)\n",
    "print(formatted_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>cos1</th>\n",
       "      <th>cos2</th>\n",
       "      <th>cos3</th>\n",
       "      <th>knn1</th>\n",
       "      <th>knn2</th>\n",
       "      <th>knn3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Types of expenses covered for relocation pplic...</td>\n",
       "      <td>24,0.73167514891693</td>\n",
       "      <td>26,0.7234795860880974</td>\n",
       "      <td>25,0.7206877359265444</td>\n",
       "      <td>26,16.31082082206285</td>\n",
       "      <td>24,16.39321315582947</td>\n",
       "      <td>25,16.624978481821927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What are half yearly awards</td>\n",
       "      <td>33,0.6012876925602934</td>\n",
       "      <td>34,0.5745539086034994</td>\n",
       "      <td>32,0.5488804145321222</td>\n",
       "      <td>33,19.63542295501611</td>\n",
       "      <td>34,20.477088664374605</td>\n",
       "      <td>32,21.018170781212348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is the criteria for PAT on the back</td>\n",
       "      <td>36,0.4221254111180226</td>\n",
       "      <td>58,0.38948894705687287</td>\n",
       "      <td>33,0.38037380928989345</td>\n",
       "      <td>36,23.795754771310385</td>\n",
       "      <td>58,24.214489592352038</td>\n",
       "      <td>33,24.60175469755268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question                   cos1  \\\n",
       "0  Types of expenses covered for relocation pplic...    24,0.73167514891693   \n",
       "1                        What are half yearly awards  33,0.6012876925602934   \n",
       "2           What is the criteria for PAT on the back  36,0.4221254111180226   \n",
       "\n",
       "                     cos2                    cos3                   knn1  \\\n",
       "0   26,0.7234795860880974   25,0.7206877359265444   26,16.31082082206285   \n",
       "1   34,0.5745539086034994   32,0.5488804145321222   33,19.63542295501611   \n",
       "2  58,0.38948894705687287  33,0.38037380928989345  36,23.795754771310385   \n",
       "\n",
       "                    knn2                   knn3  \n",
       "0   24,16.39321315582947  25,16.624978481821927  \n",
       "1  34,20.477088664374605  32,21.018170781212348  \n",
       "2  58,24.214489592352038   33,24.60175469755268  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# df_=pd.DataFrame(formatted_output)\n",
    "columns = ['question', 'cos1', 'cos2', 'cos3', 'knn1', 'knn2', 'knn3']\n",
    "\n",
    "# Create the DataFrame\n",
    "df = pd.DataFrame(formatted_output, columns=columns)\n",
    "\n",
    "# Display the DataFrame\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
